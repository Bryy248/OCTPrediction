{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4b0f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAHE destination 'dataset_clahe' exists and not empty. Skipping CLAHE.\n",
      "Detected classes: ['AMD', 'CNV', 'CSR', 'DME', 'DR', 'DRUSEN', 'MH', 'NORMAL']\n",
      "Found 18400 files belonging to 8 classes.\n",
      "Found 2800 files belonging to 8 classes.\n",
      "steps_per_epoch (estimate): 575\n",
      "Building models (EffNetV2, ResNet50V2, SimpleCNN)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EffNetV2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EffNetV2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-b0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-b0 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m5,919,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │         \u001b[38;5;34m5,120\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m655,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,647,000</span> (25.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,647,000\u001b[0m (25.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,136,564</span> (19.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,136,564\u001b[0m (19.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,510,436</span> (5.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,510,436\u001b[0m (5.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResNet50V2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ResNet50V2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ true_divide_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ subtract_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,104</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ true_divide_1 (\u001b[38;5;33mTrueDivide\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ subtract_1 (\u001b[38;5;33mSubtract\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m4,104\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,626,184</span> (93.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,626,184\u001b[0m (93.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,498,952</span> (78.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,498,952\u001b[0m (78.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,127,232</span> (15.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,127,232\u001b[0m (15.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SimpleCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_5 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,328</span> (501.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,328\u001b[0m (501.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,328</span> (501.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,328\u001b[0m (501.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\DL\\environments\\deep_learning\\Lib\\site-packages\\keras\\src\\callbacks\\tensorboard.py:680: UserWarning: Model failed to serialize as JSON. Ignoring... Learning rate schedule '_LR' must override `get_config()` in order to be serializable.\n",
      "  warnings.warn(f\"Model failed to serialize as JSON. Ignoring... {exc}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956ms/step - accuracy: 0.1737 - loss: 2.7181"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Learning rate schedule '_LR' must override `get_config()` in order to be serializable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 424\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28mprint\u001b[39m(cnn.summary())\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# Train models\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m \u001b[43mcompile_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43meffnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43meffnetv2_finetuned\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m compile_and_train(resnet, train_ds, val_ds, model_name=\u001b[33m'\u001b[39m\u001b[33mresnet50v2_finetuned\u001b[39m\u001b[33m'\u001b[39m, epochs=EPOCHS, base_lr=\u001b[32m1e-4\u001b[39m, warmup_epochs=\u001b[32m3\u001b[39m)\n\u001b[32m    426\u001b[39m compile_and_train(cnn, train_ds, val_ds, model_name=\u001b[33m'\u001b[39m\u001b[33msimplecnn\u001b[39m\u001b[33m'\u001b[39m, epochs=EPOCHS, base_lr=\u001b[32m1e-4\u001b[39m, warmup_epochs=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 318\u001b[39m, in \u001b[36mcompile_and_train\u001b[39m\u001b[34m(model, train_ds, val_ds, model_name, epochs, base_lr, warmup_epochs)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m     ema_cb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m# if EMA used, ensure final weights are ema for evaluation and saving\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ema_cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python\\DL\\environments\\deep_learning\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python\\DL\\environments\\deep_learning\\Lib\\site-packages\\keras\\src\\optimizers\\schedules\\learning_rate_schedule.py:61\u001b[39m, in \u001b[36mLearningRateSchedule.get_config\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m     62\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLearning rate schedule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmust override `get_config()` in order to be serializable.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     64\u001b[39m     )\n",
      "\u001b[31mNotImplementedError\u001b[39m: Learning rate schedule '_LR' must override `get_config()` in order to be serializable."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Super-clean pipeline: EfficientNetV2 + ResNet50V2 + SimpleCNN ensemble\n",
    "Includes:\n",
    "- INPUT_SIZE = (224,224)\n",
    "- Optional CLAHE offline preprocessing (guarded)\n",
    "- tf.data pipeline with correct cache/shuffle/prefetch order\n",
    "- Data augmentation\n",
    "- Warmup + CosineDecay LR schedule\n",
    "- AdamW optimizer\n",
    "- EMA (Exponential Moving Average) callback\n",
    "- Per-model checkpoint folders (.keras SavedModel)\n",
    "- TTA (with augmentation forced during TTA)\n",
    "- PSO for ensemble weight search (configurable particles/iters)\n",
    "- Logging to CSV and TensorBoard\n",
    "\n",
    "How to use:\n",
    "- Fill DATA_DIR with train/val subfolders\n",
    "- Set USE_CLAHE_PREPROCESS=True if you want CLAHE applied (will write to dataset_clahe once)\n",
    "- Run: python super_pipeline.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import cv2\n",
    "\n",
    "# ---------------------- USER CONFIG ----------------------\n",
    "DATA_DIR = \"RetinalOCT_Dataset\"  # root dir containing 'train' and 'val' subfolders\n",
    "PREPROCESSED_DIR = \"dataset_clahe\"\n",
    "INPUT_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 8\n",
    "SEED = 42\n",
    "EPOCHS = 50\n",
    "MODEL_DIR = \"models\"\n",
    "LOG_DIR = \"logs\"\n",
    "USE_CLAHE_PREPROCESS = True  # if True, CLAHE will be applied once and saved to PREPROCESSED_DIR\n",
    "USE_EMA = True\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "PSO_PARTICLES = 20\n",
    "PSO_ITERS = 150\n",
    "TTA_STEPS = 5\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------- UTILITIES ----------------------\n",
    "\n",
    "def list_classes(path):\n",
    "    return sorted([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])\n",
    "\n",
    "# ---------------------- CLAHE PREPROCESS (offline, guarded) ----------------------\n",
    "\n",
    "def apply_clahe_to_folder(src_root, dst_root, size=INPUT_SIZE):\n",
    "    if os.path.exists(dst_root) and any(os.scandir(dst_root)):\n",
    "        print(f\"CLAHE destination '{dst_root}' exists and not empty. Skipping CLAHE.\")\n",
    "        return\n",
    "    print(\"Running CLAHE preprocessing (this may take a while)...\")\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        src_split = os.path.join(src_root, split)\n",
    "        dst_split = os.path.join(dst_root, split)\n",
    "        if not os.path.exists(src_split):\n",
    "            print(f\"Warning: {src_split} not found. Skipping.\")\n",
    "            continue\n",
    "        for class_name in os.listdir(src_split):\n",
    "            src_cls = os.path.join(src_split, class_name)\n",
    "            dst_cls = os.path.join(dst_split, class_name)\n",
    "            os.makedirs(dst_cls, exist_ok=True)\n",
    "            for fname in os.listdir(src_cls):\n",
    "                src_path = os.path.join(src_cls, fname)\n",
    "                dst_path = os.path.join(dst_cls, fname)\n",
    "                img = cv2.imread(src_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, size)\n",
    "                lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "                l, a, b = cv2.split(lab)\n",
    "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "                cl = clahe.apply(l)\n",
    "                limg = cv2.merge((cl, a, b))\n",
    "                out = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "                cv2.imwrite(dst_path, cv2.cvtColor(out, cv2.COLOR_RGB2BGR))\n",
    "    print(\"CLAHE preprocessing finished.\")\n",
    "\n",
    "# ---------------------- DATA PIPELINE ----------------------\n",
    "if USE_CLAHE_PREPROCESS:\n",
    "    apply_clahe_to_folder(DATA_DIR, PREPROCESSED_DIR)\n",
    "    DATA_DIR_USED = PREPROCESSED_DIR\n",
    "else:\n",
    "    DATA_DIR_USED = DATA_DIR\n",
    "\n",
    "# sanity check classes\n",
    "train_root = os.path.join(DATA_DIR_USED, 'train')\n",
    "if not os.path.exists(train_root):\n",
    "    raise FileNotFoundError(f\"Train directory not found: {train_root}\")\n",
    "\n",
    "classes = list_classes(train_root)\n",
    "print(f\"Detected classes: {classes}\")\n",
    "\n",
    "# dataset loaders\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR_USED, 'train'),\n",
    "    image_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int',\n",
    "    seed=SEED\n",
    ")\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR_USED, 'val'),\n",
    "    image_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# recommended order: shuffle -> map -> cache -> prefetch\n",
    "train_ds = train_ds.shuffle(1000, seed=SEED).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# compute steps_per_epoch safely\n",
    "try:\n",
    "    steps_per_epoch = int(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "    if steps_per_epoch <= 0:\n",
    "        steps_per_epoch = None\n",
    "except Exception:\n",
    "    steps_per_epoch = None\n",
    "\n",
    "print(f\"steps_per_epoch (estimate): {steps_per_epoch}\")\n",
    "\n",
    "# augmentation pipeline\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.08),\n",
    "    layers.RandomZoom(0.08),\n",
    "    layers.RandomContrast(0.12),\n",
    "], name='data_augmentation')\n",
    "\n",
    "# ---------------------- MODEL BUILDERS ----------------------\n",
    "from tensorflow.keras.applications import efficientnet_v2, resnet_v2\n",
    "\n",
    "\n",
    "def build_effnet(input_shape=(*INPUT_SIZE,3), num_classes=NUM_CLASSES, fine_tune_at=120):\n",
    "    try:\n",
    "        base = efficientnet_v2.EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "        preprocess = efficientnet_v2.preprocess_input\n",
    "    except Exception:\n",
    "        base = keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "        preprocess = keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess(x)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name='EffNetV2')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_resnet(input_shape=(*INPUT_SIZE,3), num_classes=NUM_CLASSES, fine_tune_at=80):\n",
    "    base = resnet_v2.ResNet50V2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    preprocess = resnet_v2.preprocess_input\n",
    "\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess(x)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name='ResNet50V2')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_simple_cnn(input_shape=(*INPUT_SIZE,3), num_classes=NUM_CLASSES):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Rescaling(1./255)(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name='SimpleCNN')\n",
    "    return model\n",
    "\n",
    "# ---------------------- SCHEDULERS / OPTIMIZER / EMA ----------------------\n",
    "\n",
    "class WarmUpCosineDecay:\n",
    "    def __init__(self, base_lr, total_steps, warmup_steps=0, alpha=0.0):\n",
    "        self.base_lr = base_lr\n",
    "        self.total_steps = max(1, int(total_steps))\n",
    "        self.warmup_steps = int(warmup_steps)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        if self.warmup_steps > 0:\n",
    "            warmup_pct = tf.minimum(1.0, step / tf.cast(self.warmup_steps, tf.float32))\n",
    "            warmup_lr = self.base_lr * warmup_pct\n",
    "        else:\n",
    "            warmup_lr = self.base_lr\n",
    "\n",
    "        # cosine after warmup\n",
    "        progress = (step - self.warmup_steps) / tf.maximum(1.0, (self.total_steps - self.warmup_steps))\n",
    "        cosine_lr = self.alpha + 0.5 * (1.0 - self.alpha) * (1.0 + tf.cos(math.pi * tf.clip_by_value(progress, 0.0, 1.0)))\n",
    "        cosine_lr = self.base_lr * cosine_lr\n",
    "\n",
    "        return tf.where(step < self.warmup_steps, warmup_lr, cosine_lr)\n",
    "\n",
    "class ExponentialMovingAverageCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, ema_decay=0.9999):\n",
    "        super().__init__()\n",
    "        self.ema_decay = ema_decay\n",
    "        self.ema_weights = None\n",
    "\n",
    "    def set_model(self, model):\n",
    "        super().set_model(model)\n",
    "        # initialize shadow weights\n",
    "        self.ema_weights = [tf.identity(w) for w in model.get_weights()]\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        weights = self.model.get_weights()\n",
    "        for i in range(len(weights)):\n",
    "            self.ema_weights[i] = self.ema_decay * self.ema_weights[i] + (1.0 - self.ema_decay) * weights[i]\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # save current weights and set ema weights for final evaluation / saving\n",
    "        self._backup = self.model.get_weights()\n",
    "        self.model.set_weights(self.ema_weights)\n",
    "\n",
    "    def restore(self):\n",
    "        if hasattr(self, '_backup'):\n",
    "            self.model.set_weights(self._backup)\n",
    "\n",
    "# ---------------------- TRAIN UTIL ----------------------\n",
    "\n",
    "def compile_and_train(model, train_ds, val_ds, model_name, epochs=EPOCHS, base_lr=1e-4, warmup_epochs=3):\n",
    "    # per-model folder\n",
    "    ckpt_dir = os.path.join(MODEL_DIR, model_name)\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    log_dir = os.path.join(LOG_DIR, model_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # compute total steps\n",
    "    if steps_per_epoch is None:\n",
    "        # fallback: iterate once to count\n",
    "        cnt = 0\n",
    "        for _ in train_ds:\n",
    "            cnt += 1\n",
    "        sperep = max(1, cnt)\n",
    "    else:\n",
    "        sperep = steps_per_epoch\n",
    "    total_steps = sperep * epochs\n",
    "    warmup_steps = sperep * warmup_epochs\n",
    "\n",
    "    # lr schedule\n",
    "    schedules = WarmUpCosineDecay(base_lr, total_steps, warmup_steps=warmup_steps, alpha=0.0)\n",
    "    lr_fn = lambda step: schedules(step)\n",
    "    lr_schedule = keras.optimizers.schedules.LearningRateSchedule()\n",
    "    # wrapcustom as a tf.function-compatible schedule\n",
    "    class _LR(keras.optimizers.schedules.LearningRateSchedule):\n",
    "        def __call__(self, step):\n",
    "            return schedules(step)\n",
    "    lr_schedule = _LR()\n",
    "\n",
    "    optimizer = keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-5)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = []\n",
    "    callbacks.append(keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(ckpt_dir, f\"{model_name}.keras\"),\n",
    "        save_best_only=True, save_weights_only=False, monitor='val_accuracy'\n",
    "    ))\n",
    "    callbacks.append(keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7))\n",
    "    callbacks.append(keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True))\n",
    "    callbacks.append(keras.callbacks.CSVLogger(os.path.join(log_dir, 'history.csv')))\n",
    "    callbacks.append(keras.callbacks.TensorBoard(log_dir=log_dir))\n",
    "    if USE_EMA:\n",
    "        ema_cb = ExponentialMovingAverageCallback(ema_decay=0.9999)\n",
    "        callbacks.append(ema_cb)\n",
    "    else:\n",
    "        ema_cb = None\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
    "\n",
    "    # if EMA used, ensure final weights are ema for evaluation and saving\n",
    "    if ema_cb is not None:\n",
    "        print(\"Applying EMA weights for final evaluation and saving...\")\n",
    "        ema_cb.on_train_end()\n",
    "\n",
    "    # save final model copy (best already saved by checkpoint)\n",
    "    final_path = os.path.join(ckpt_dir, f\"{model_name}_final.keras\")\n",
    "    model.save(final_path)\n",
    "    print(f\"Saved final model to: {final_path}\")\n",
    "\n",
    "    # restore model if EMA backup exists (so model object remains original for further training)\n",
    "    if ema_cb is not None:\n",
    "        ema_cb.restore()\n",
    "\n",
    "    return history\n",
    "\n",
    "# ---------------------- TTA (with augmentation enabled) ----------------------\n",
    "\n",
    "def predict_with_tta(model, dataset, tta_steps=TTA_STEPS):\n",
    "    probs = []\n",
    "    for x_batch, _ in dataset:\n",
    "        x0 = tf.cast(x_batch, tf.float32)\n",
    "        batch_probs = np.zeros((x0.shape[0], NUM_CLASSES), dtype=np.float32)\n",
    "        for t in range(tta_steps):\n",
    "            aug = data_augmentation(x0, training=True)\n",
    "            preds = model.predict(aug, verbose=0)\n",
    "            batch_probs += preds\n",
    "        batch_probs /= float(tta_steps)\n",
    "        probs.append(batch_probs)\n",
    "    probs = np.vstack(probs)\n",
    "    return probs\n",
    "\n",
    "# ---------------------- ENSEMBLE / PSO ----------------------\n",
    "\n",
    "def ensemble_average(probs_list):\n",
    "    return np.mean(np.stack(probs_list, axis=0), axis=0)\n",
    "\n",
    "def ensemble_weighted(probs_list, weights):\n",
    "    w = np.array(weights).reshape(-1,1,1)\n",
    "    stacked = np.stack(probs_list, axis=0)\n",
    "    combined = np.sum(w * stacked, axis=0)\n",
    "    return combined\n",
    "\n",
    "class SimplePSO:\n",
    "    def __init__(self, n_particles, dim, probs_list, y_true, iters=100, w=0.72, c1=1.49, c2=1.49):\n",
    "        self.n_particles = n_particles\n",
    "        self.dim = dim\n",
    "        self.probs_list = probs_list\n",
    "        self.y_true = y_true\n",
    "        self.iters = iters\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.pos = np.random.rand(n_particles, dim)\n",
    "        self.pos = self.pos / np.sum(self.pos, axis=1, keepdims=True)\n",
    "        self.vel = np.zeros_like(self.pos)\n",
    "        self.pbest_pos = self.pos.copy()\n",
    "        self.pbest_val = np.array([self._fitness(p) for p in self.pos])\n",
    "        self.gbest_idx = np.argmin(self.pbest_val)\n",
    "        self.gbest_pos = self.pbest_pos[self.gbest_idx].copy()\n",
    "        self.gbest_val = self.pbest_val[self.gbest_idx]\n",
    "\n",
    "    def _fitness(self, weights):\n",
    "        combined = np.zeros_like(self.probs_list[0])\n",
    "        for w, probs in zip(weights, self.probs_list):\n",
    "            combined += w * probs\n",
    "        preds = np.argmax(combined, axis=1)\n",
    "        acc = accuracy_score(self.y_true, preds)\n",
    "        return -acc\n",
    "\n",
    "    def optimize(self):\n",
    "        for it in range(self.iters):\n",
    "            r1 = np.random.rand(self.n_particles, self.dim)\n",
    "            r2 = np.random.rand(self.n_particles, self.dim)\n",
    "            cognitive = self.c1 * r1 * (self.pbest_pos - self.pos)\n",
    "            social = self.c2 * r2 * (self.gbest_pos - self.pos)\n",
    "            self.vel = self.w * self.vel + cognitive + social\n",
    "            self.pos = self.pos + self.vel\n",
    "            self.pos = np.clip(self.pos, 1e-6, None)\n",
    "            self.pos = self.pos / np.sum(self.pos, axis=1, keepdims=True)\n",
    "            vals = np.array([self._fitness(p) for p in self.pos])\n",
    "            improved = vals < self.pbest_val\n",
    "            self.pbest_val[improved] = vals[improved]\n",
    "            self.pbest_pos[improved] = self.pos[improved]\n",
    "            gidx = np.argmin(self.pbest_val)\n",
    "            if self.pbest_val[gidx] < self.gbest_val:\n",
    "                self.gbest_val = self.pbest_val[gidx]\n",
    "                self.gbest_pos = self.pbest_pos[gidx].copy()\n",
    "            if it % max(1, self.iters//10) == 0 or it == self.iters - 1:\n",
    "                print(f\"PSO iter {it+1}/{self.iters}, best_acc = {-self.gbest_val:.4f}\")\n",
    "        return self.gbest_pos, -self.gbest_val\n",
    "\n",
    "# ---------------------- MAIN WORKFLOW ----------------------\n",
    "if __name__ == '__main__':\n",
    "    print(\"Building models (EffNetV2, ResNet50V2, SimpleCNN)\")\n",
    "    effnet = build_effnet(fine_tune_at=120)\n",
    "    resnet = build_resnet(fine_tune_at=80)\n",
    "    cnn = build_simple_cnn()\n",
    "\n",
    "    print(effnet.summary())\n",
    "    print(resnet.summary())\n",
    "    print(cnn.summary())\n",
    "\n",
    "    # Train models\n",
    "    compile_and_train(effnet, train_ds, val_ds, model_name='effnetv2_finetuned', epochs=EPOCHS, base_lr=1e-4, warmup_epochs=3)\n",
    "    compile_and_train(resnet, train_ds, val_ds, model_name='resnet50v2_finetuned', epochs=EPOCHS, base_lr=1e-4, warmup_epochs=3)\n",
    "    compile_and_train(cnn, train_ds, val_ds, model_name='simplecnn', epochs=EPOCHS, base_lr=1e-4, warmup_epochs=2)\n",
    "\n",
    "    # Evaluate with TTA\n",
    "    print(\"Computing TTA predictions (this may take a while)\")\n",
    "    eff_probs = predict_with_tta(effnet, val_ds, tta_steps=TTA_STEPS)\n",
    "    res_probs = predict_with_tta(resnet, val_ds, tta_steps=TTA_STEPS)\n",
    "    cnn_probs = predict_with_tta(cnn, val_ds, tta_steps=TTA_STEPS)\n",
    "\n",
    "    y_true = np.concatenate([y.numpy() for _, y in val_ds], axis=0)\n",
    "\n",
    "    # Simple average\n",
    "    avg_probs = ensemble_average([eff_probs, res_probs, cnn_probs])\n",
    "    avg_pred = np.argmax(avg_probs, axis=1)\n",
    "    avg_acc = accuracy_score(y_true, avg_pred)\n",
    "    print(f\"Average ensemble accuracy: {avg_acc:.4f}\")\n",
    "    print(classification_report(y_true, avg_pred))\n",
    "\n",
    "    # PSO optimize\n",
    "    print(\"Running PSO to find best ensemble weights...\")\n",
    "    pso = SimplePSO(n_particles=PSO_PARTICLES, dim=3, probs_list=[eff_probs, res_probs, cnn_probs], y_true=y_true, iters=PSO_ITERS)\n",
    "    best_w, best_acc = pso.optimize()\n",
    "    print(f\"Best weights: {best_w}, best_acc: {best_acc:.4f}\")\n",
    "\n",
    "    combined = ensemble_weighted([eff_probs, res_probs, cnn_probs], best_w)\n",
    "    comb_pred = np.argmax(combined, axis=1)\n",
    "    print(classification_report(y_true, comb_pred))\n",
    "\n",
    "    np.save(os.path.join(MODEL_DIR, 'ensemble_weights_3models.npy'), best_w)\n",
    "    print(\"All done. Models and ensemble weights saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9b80e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAHE destination 'dataset_clahe' exists and not empty. Skipping CLAHE.\n",
      "Detected classes: ['AMD', 'CNV', 'CSR', 'DME', 'DR', 'DRUSEN', 'MH', 'NORMAL']\n",
      "Found 18400 files belonging to 8 classes.\n",
      "Found 2800 files belonging to 8 classes.\n",
      "steps_per_epoch (estimate): 575\n",
      "Building models (EffNetV2, ResNet50V2, SimpleCNN)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EffNetV2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EffNetV2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-b0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_17     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_35 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-b0 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m5,919,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_17     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │         \u001b[38;5;34m5,120\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m655,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,647,000</span> (25.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,647,000\u001b[0m (25.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,136,564</span> (19.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,136,564\u001b[0m (19.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,510,436</span> (5.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,510,436\u001b[0m (5.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResNet50V2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ResNet50V2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ true_divide_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ subtract_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_18     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,104</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_38 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ true_divide_5 (\u001b[38;5;33mTrueDivide\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ subtract_5 (\u001b[38;5;33mSubtract\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_18     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m4,104\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,626,184</span> (93.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,626,184\u001b[0m (93.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,498,952</span> (78.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,498,952\u001b[0m (78.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,127,232</span> (15.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,127,232\u001b[0m (15.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SimpleCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_19     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_39 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_13 (\u001b[38;5;33mRescaling\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_36 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_37 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_38 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_19     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,328</span> (501.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,328\u001b[0m (501.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,328</span> (501.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,328\u001b[0m (501.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 1s/step - accuracy: 0.7198 - loss: 0.7860 - val_accuracy: 0.9182 - val_loss: 0.2171 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 942ms/step - accuracy: 0.8968 - loss: 0.2963 - val_accuracy: 0.9300 - val_loss: 0.1796 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 989ms/step - accuracy: 0.9230 - loss: 0.2259 - val_accuracy: 0.9425 - val_loss: 0.1547 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 977ms/step - accuracy: 0.9324 - loss: 0.1939 - val_accuracy: 0.9450 - val_loss: 0.1464 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 987ms/step - accuracy: 0.9411 - loss: 0.1677 - val_accuracy: 0.9511 - val_loss: 0.1342 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 967ms/step - accuracy: 0.9477 - loss: 0.1589 - val_accuracy: 0.9475 - val_loss: 0.1457 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 968ms/step - accuracy: 0.9515 - loss: 0.1403 - val_accuracy: 0.9461 - val_loss: 0.1491 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 970ms/step - accuracy: 0.9551 - loss: 0.1323 - val_accuracy: 0.9436 - val_loss: 0.1557 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 969ms/step - accuracy: 0.9619 - loss: 0.1091 - val_accuracy: 0.9543 - val_loss: 0.1352 - learning_rate: 5.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 982ms/step - accuracy: 0.9638 - loss: 0.1016 - val_accuracy: 0.9543 - val_loss: 0.1421 - learning_rate: 5.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m574s\u001b[0m 998ms/step - accuracy: 0.9660 - loss: 0.0980 - val_accuracy: 0.9557 - val_loss: 0.1306 - learning_rate: 5.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 1s/step - accuracy: 0.9670 - loss: 0.0938 - val_accuracy: 0.9514 - val_loss: 0.1479 - learning_rate: 5.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 916ms/step - accuracy: 0.9705 - loss: 0.0875 - val_accuracy: 0.9514 - val_loss: 0.1438 - learning_rate: 5.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 960ms/step - accuracy: 0.9721 - loss: 0.0800 - val_accuracy: 0.9550 - val_loss: 0.1508 - learning_rate: 5.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 990ms/step - accuracy: 0.9749 - loss: 0.0709 - val_accuracy: 0.9568 - val_loss: 0.1430 - learning_rate: 2.5000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 993ms/step - accuracy: 0.9749 - loss: 0.0729 - val_accuracy: 0.9550 - val_loss: 0.1429 - learning_rate: 2.5000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 978ms/step - accuracy: 0.9770 - loss: 0.0658 - val_accuracy: 0.9575 - val_loss: 0.1369 - learning_rate: 2.5000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m590s\u001b[0m 1s/step - accuracy: 0.9774 - loss: 0.0625 - val_accuracy: 0.9561 - val_loss: 0.1402 - learning_rate: 1.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 1s/step - accuracy: 0.9797 - loss: 0.0572 - val_accuracy: 0.9550 - val_loss: 0.1415 - learning_rate: 1.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 1s/step - accuracy: 0.9790 - loss: 0.0579 - val_accuracy: 0.9561 - val_loss: 0.1419 - learning_rate: 1.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 1s/step - accuracy: 0.9819 - loss: 0.0519 - val_accuracy: 0.9557 - val_loss: 0.1430 - learning_rate: 6.2500e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 1s/step - accuracy: 0.9811 - loss: 0.0559 - val_accuracy: 0.9557 - val_loss: 0.1440 - learning_rate: 6.2500e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 1s/step - accuracy: 0.9812 - loss: 0.0535 - val_accuracy: 0.9568 - val_loss: 0.1437 - learning_rate: 6.2500e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 1s/step - accuracy: 0.9817 - loss: 0.0519 - val_accuracy: 0.9568 - val_loss: 0.1440 - learning_rate: 3.1250e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 1s/step - accuracy: 0.9811 - loss: 0.0522 - val_accuracy: 0.9568 - val_loss: 0.1445 - learning_rate: 3.1250e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 1s/step - accuracy: 0.9821 - loss: 0.0501 - val_accuracy: 0.9557 - val_loss: 0.1472 - learning_rate: 3.1250e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 1s/step - accuracy: 0.9823 - loss: 0.0525 - val_accuracy: 0.9564 - val_loss: 0.1470 - learning_rate: 1.5625e-06\n",
      "EMA applied at training end (if available).\n",
      "Saved final model to: models\\effnetv2_finetuned\\effnetv2_finetuned_final.keras\n",
      "Epoch 1/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1524s\u001b[0m 3s/step - accuracy: 0.8510 - loss: 0.4348 - val_accuracy: 0.9289 - val_loss: 0.1952 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1542s\u001b[0m 3s/step - accuracy: 0.9361 - loss: 0.1877 - val_accuracy: 0.9489 - val_loss: 0.1518 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 3s/step - accuracy: 0.9473 - loss: 0.1565 - val_accuracy: 0.9493 - val_loss: 0.1691 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1503s\u001b[0m 3s/step - accuracy: 0.9547 - loss: 0.1361 - val_accuracy: 0.9414 - val_loss: 0.1654 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1464s\u001b[0m 3s/step - accuracy: 0.9584 - loss: 0.1270 - val_accuracy: 0.9486 - val_loss: 0.1617 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1538s\u001b[0m 3s/step - accuracy: 0.9694 - loss: 0.0915 - val_accuracy: 0.9596 - val_loss: 0.1171 - learning_rate: 5.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1528s\u001b[0m 3s/step - accuracy: 0.9743 - loss: 0.0753 - val_accuracy: 0.9600 - val_loss: 0.1274 - learning_rate: 5.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1540s\u001b[0m 3s/step - accuracy: 0.9753 - loss: 0.0675 - val_accuracy: 0.9450 - val_loss: 0.1938 - learning_rate: 5.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1540s\u001b[0m 3s/step - accuracy: 0.9765 - loss: 0.0668 - val_accuracy: 0.9575 - val_loss: 0.1498 - learning_rate: 5.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1536s\u001b[0m 3s/step - accuracy: 0.9841 - loss: 0.0488 - val_accuracy: 0.9607 - val_loss: 0.1361 - learning_rate: 2.5000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1342s\u001b[0m 2s/step - accuracy: 0.9859 - loss: 0.0429 - val_accuracy: 0.9675 - val_loss: 0.1179 - learning_rate: 2.5000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1335s\u001b[0m 2s/step - accuracy: 0.9865 - loss: 0.0363 - val_accuracy: 0.9639 - val_loss: 0.1350 - learning_rate: 2.5000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1337s\u001b[0m 2s/step - accuracy: 0.9909 - loss: 0.0284 - val_accuracy: 0.9625 - val_loss: 0.1352 - learning_rate: 1.2500e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1340s\u001b[0m 2s/step - accuracy: 0.9918 - loss: 0.0247 - val_accuracy: 0.9618 - val_loss: 0.1360 - learning_rate: 1.2500e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1336s\u001b[0m 2s/step - accuracy: 0.9922 - loss: 0.0221 - val_accuracy: 0.9611 - val_loss: 0.1395 - learning_rate: 1.2500e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1327s\u001b[0m 2s/step - accuracy: 0.9943 - loss: 0.0179 - val_accuracy: 0.9639 - val_loss: 0.1404 - learning_rate: 6.2500e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1314s\u001b[0m 2s/step - accuracy: 0.9941 - loss: 0.0172 - val_accuracy: 0.9646 - val_loss: 0.1409 - learning_rate: 6.2500e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1314s\u001b[0m 2s/step - accuracy: 0.9955 - loss: 0.0141 - val_accuracy: 0.9650 - val_loss: 0.1399 - learning_rate: 6.2500e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1320s\u001b[0m 2s/step - accuracy: 0.9959 - loss: 0.0127 - val_accuracy: 0.9643 - val_loss: 0.1353 - learning_rate: 3.1250e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1315s\u001b[0m 2s/step - accuracy: 0.9964 - loss: 0.0115 - val_accuracy: 0.9654 - val_loss: 0.1378 - learning_rate: 3.1250e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1316s\u001b[0m 2s/step - accuracy: 0.9958 - loss: 0.0122 - val_accuracy: 0.9646 - val_loss: 0.1382 - learning_rate: 3.1250e-06\n",
      "EMA applied at training end (if available).\n",
      "Saved final model to: models\\resnet50v2_finetuned\\resnet50v2_finetuned_final.keras\n",
      "Epoch 1/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 494ms/step - accuracy: 0.2692 - loss: 1.7765 - val_accuracy: 0.2129 - val_loss: 2.8353 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 501ms/step - accuracy: 0.3565 - loss: 1.3931 - val_accuracy: 0.2086 - val_loss: 3.1639 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 507ms/step - accuracy: 0.3802 - loss: 1.2566 - val_accuracy: 0.2189 - val_loss: 3.2014 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 506ms/step - accuracy: 0.3835 - loss: 1.2128 - val_accuracy: 0.2057 - val_loss: 3.6293 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 500ms/step - accuracy: 0.3932 - loss: 1.1861 - val_accuracy: 0.2068 - val_loss: 3.7549 - learning_rate: 5.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 500ms/step - accuracy: 0.3997 - loss: 1.1794 - val_accuracy: 0.2068 - val_loss: 3.9523 - learning_rate: 5.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 501ms/step - accuracy: 0.4030 - loss: 1.1690 - val_accuracy: 0.2154 - val_loss: 3.7398 - learning_rate: 5.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 501ms/step - accuracy: 0.4018 - loss: 1.1621 - val_accuracy: 0.2039 - val_loss: 4.0559 - learning_rate: 2.5000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 501ms/step - accuracy: 0.4039 - loss: 1.1639 - val_accuracy: 0.2143 - val_loss: 3.6171 - learning_rate: 2.5000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 503ms/step - accuracy: 0.4018 - loss: 1.1594 - val_accuracy: 0.2164 - val_loss: 3.4441 - learning_rate: 2.5000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 499ms/step - accuracy: 0.4031 - loss: 1.1552 - val_accuracy: 0.2189 - val_loss: 3.4267 - learning_rate: 1.2500e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 504ms/step - accuracy: 0.4038 - loss: 1.1532 - val_accuracy: 0.2129 - val_loss: 3.6865 - learning_rate: 1.2500e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 506ms/step - accuracy: 0.4061 - loss: 1.1528 - val_accuracy: 0.2125 - val_loss: 3.7237 - learning_rate: 1.2500e-05\n",
      "EMA applied at training end (if available).\n",
      "Saved final model to: models\\simplecnn\\simplecnn_final.keras\n",
      "Computing TTA predictions (this may take a while)\n",
      "Average ensemble accuracy: 0.9707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       350\n",
      "           1       0.95      0.94      0.95       350\n",
      "           2       1.00      1.00      1.00       350\n",
      "           3       0.96      0.95      0.95       350\n",
      "           4       1.00      1.00      1.00       350\n",
      "           5       0.94      0.90      0.92       350\n",
      "           6       1.00      1.00      1.00       350\n",
      "           7       0.92      0.97      0.94       350\n",
      "\n",
      "    accuracy                           0.97      2800\n",
      "   macro avg       0.97      0.97      0.97      2800\n",
      "weighted avg       0.97      0.97      0.97      2800\n",
      "\n",
      "Running PSO to find best ensemble weights...\n",
      "PSO iter 1/150, best_acc = 0.9714\n",
      "PSO iter 16/150, best_acc = 0.9718\n",
      "PSO iter 31/150, best_acc = 0.9718\n",
      "PSO iter 46/150, best_acc = 0.9718\n",
      "PSO iter 61/150, best_acc = 0.9718\n",
      "PSO iter 76/150, best_acc = 0.9718\n",
      "PSO iter 91/150, best_acc = 0.9718\n",
      "PSO iter 106/150, best_acc = 0.9718\n",
      "PSO iter 121/150, best_acc = 0.9718\n",
      "PSO iter 136/150, best_acc = 0.9718\n",
      "PSO iter 150/150, best_acc = 0.9718\n",
      "Best weights: [0.23248473 0.45600428 0.311511  ], best_acc: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       350\n",
      "           1       0.96      0.94      0.95       350\n",
      "           2       1.00      1.00      1.00       350\n",
      "           3       0.95      0.95      0.95       350\n",
      "           4       1.00      1.00      1.00       350\n",
      "           5       0.94      0.91      0.93       350\n",
      "           6       1.00      1.00      1.00       350\n",
      "           7       0.92      0.97      0.95       350\n",
      "\n",
      "    accuracy                           0.97      2800\n",
      "   macro avg       0.97      0.97      0.97      2800\n",
      "weighted avg       0.97      0.97      0.97      2800\n",
      "\n",
      "All done. Models and ensemble weights saved.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Super-clean pipeline (final, error-free):\n",
    "EfficientNetV2 + ResNet50V2 + SimpleCNN ensemble with PSO weight search,\n",
    "optional CLAHE preprocessing, EMA, TTA, AdamW optimizer.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import cv2\n",
    "\n",
    "# ---------------------- USER CONFIG ----------------------\n",
    "DATA_DIR = \"RetinalOCT_Dataset\"      # must contain train/val subfolders\n",
    "PREPROCESSED_DIR = \"dataset_clahe\"\n",
    "INPUT_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 8\n",
    "SEED = 42\n",
    "EPOCHS = 50\n",
    "MODEL_DIR = \"models\"\n",
    "LOG_DIR = \"logs\"\n",
    "USE_CLAHE_PREPROCESS = True\n",
    "USE_EMA = True\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "PSO_PARTICLES = 20\n",
    "PSO_ITERS = 150\n",
    "TTA_STEPS = 5\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------- UTILITIES ----------------------\n",
    "def list_classes(path):\n",
    "    return sorted([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])\n",
    "\n",
    "# ---------------------- CLAHE PREPROCESS (offline, guarded) ----------------------\n",
    "def apply_clahe_to_folder(src_root, dst_root, size=INPUT_SIZE):\n",
    "    # Guard: run only if destination not exists or empty\n",
    "    if os.path.exists(dst_root) and any(os.scandir(dst_root)):\n",
    "        print(f\"CLAHE destination '{dst_root}' exists and not empty. Skipping CLAHE.\")\n",
    "        return\n",
    "    print(\"Running CLAHE preprocessing (this may take a while)...\")\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        src_split = os.path.join(src_root, split)\n",
    "        dst_split = os.path.join(dst_root, split)\n",
    "        if not os.path.exists(src_split):\n",
    "            print(f\"Warning: {src_split} not found. Skipping.\")\n",
    "            continue\n",
    "        for class_name in os.listdir(src_split):\n",
    "            src_cls = os.path.join(src_split, class_name)\n",
    "            dst_cls = os.path.join(dst_split, class_name)\n",
    "            os.makedirs(dst_cls, exist_ok=True)\n",
    "            for fname in os.listdir(src_cls):\n",
    "                src_path = os.path.join(src_cls, fname)\n",
    "                dst_path = os.path.join(dst_cls, fname)\n",
    "                img = cv2.imread(src_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, size)\n",
    "                lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "                l, a, b = cv2.split(lab)\n",
    "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "                cl = clahe.apply(l)\n",
    "                limg = cv2.merge((cl, a, b))\n",
    "                out = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "                cv2.imwrite(dst_path, cv2.cvtColor(out, cv2.COLOR_RGB2BGR))\n",
    "    print(\"CLAHE preprocessing finished.\")\n",
    "\n",
    "# ---------------------- DATA PIPELINE ----------------------\n",
    "if USE_CLAHE_PREPROCESS:\n",
    "    apply_clahe_to_folder(DATA_DIR, PREPROCESSED_DIR)\n",
    "    DATA_DIR_USED = PREPROCESSED_DIR\n",
    "else:\n",
    "    DATA_DIR_USED = DATA_DIR\n",
    "\n",
    "train_root = os.path.join(DATA_DIR_USED, 'train')\n",
    "if not os.path.exists(train_root):\n",
    "    raise FileNotFoundError(f\"Train directory not found: {train_root}\")\n",
    "\n",
    "classes = list_classes(train_root)\n",
    "print(f\"Detected classes: {classes}\")\n",
    "\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR_USED, 'train'),\n",
    "    image_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int',\n",
    "    seed=SEED\n",
    ")\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR_USED, 'val'),\n",
    "    image_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Order: shuffle -> cache -> prefetch (cache after shuffle to avoid caching shuffled order issue)\n",
    "train_ds = train_ds.shuffle(1000, seed=SEED).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# compute steps_per_epoch safely (may be None)\n",
    "try:\n",
    "    steps_per_epoch = int(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "    if steps_per_epoch <= 0:\n",
    "        steps_per_epoch = None\n",
    "except Exception:\n",
    "    steps_per_epoch = None\n",
    "print(f\"steps_per_epoch (estimate): {steps_per_epoch}\")\n",
    "\n",
    "# augmentation pipeline (used in both training and TTA)\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.08),\n",
    "    layers.RandomZoom(0.08),\n",
    "    layers.RandomContrast(0.12),\n",
    "], name='data_augmentation')\n",
    "\n",
    "# ---------------------- MODEL BUILDERS ----------------------\n",
    "from tensorflow.keras.applications import efficientnet_v2, resnet_v2\n",
    "\n",
    "def build_effnet(input_shape=(*INPUT_SIZE,3), num_classes=NUM_CLASSES, fine_tune_at=120):\n",
    "    try:\n",
    "        base = efficientnet_v2.EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "        preprocess = efficientnet_v2.preprocess_input\n",
    "    except Exception:\n",
    "        base = keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "        preprocess = keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess(x)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name='EffNetV2')\n",
    "    return model\n",
    "\n",
    "def build_resnet(input_shape=(*INPUT_SIZE,3), num_classes=NUM_CLASSES, fine_tune_at=80):\n",
    "    base = resnet_v2.ResNet50V2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    preprocess = resnet_v2.preprocess_input\n",
    "\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess(x)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name='ResNet50V2')\n",
    "    return model\n",
    "\n",
    "def build_simple_cnn(input_shape=(*INPUT_SIZE,3), num_classes=NUM_CLASSES):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Rescaling(1./255)(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name='SimpleCNN')\n",
    "    return model\n",
    "\n",
    "# ---------------------- EMA (fixed) ----------------------\n",
    "class ExponentialMovingAverageCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, ema_decay=0.9999):\n",
    "        super().__init__()\n",
    "        self.ema_decay = float(ema_decay)\n",
    "        self.ema_weights = None\n",
    "        self._backup = None\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Use parent to set internal model reference\n",
    "        super().set_model(model)\n",
    "        # store shadow weights as numpy arrays (copy)\n",
    "        self.ema_weights = [w.copy() for w in self.model.get_weights()]\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        # update shadow weights (numpy operations)\n",
    "        weights = self.model.get_weights()\n",
    "        for i in range(len(weights)):\n",
    "            # ensure ema_weights initialized\n",
    "            if self.ema_weights[i] is None:\n",
    "                self.ema_weights[i] = weights[i].copy()\n",
    "            else:\n",
    "                self.ema_weights[i] = self.ema_decay * self.ema_weights[i] + (1.0 - self.ema_decay) * weights[i]\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # backup current weights and set ema weights\n",
    "        self._backup = self.model.get_weights()\n",
    "        try:\n",
    "            self.model.set_weights(self.ema_weights)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: failed to set EMA weights on model:\", e)\n",
    "\n",
    "    def restore(self):\n",
    "        if self._backup is not None:\n",
    "            self.model.set_weights(self._backup)\n",
    "\n",
    "# ---------------------- TRAIN UTIL ----------------------\n",
    "def compile_and_train(model, train_ds, val_ds, model_name, epochs=EPOCHS, base_lr=1e-4, warmup_epochs=0):\n",
    "    ckpt_dir = os.path.join(MODEL_DIR, model_name)\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    log_dir = os.path.join(LOG_DIR, model_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # compute steps_per_epoch fallback\n",
    "    if steps_per_epoch is None:\n",
    "        cnt = 0\n",
    "        for _ in train_ds:\n",
    "            cnt += 1\n",
    "        sperep = max(1, cnt)\n",
    "    else:\n",
    "        sperep = steps_per_epoch\n",
    "\n",
    "    # optimizer (simple AdamW with fixed lr)\n",
    "    optimizer = keras.optimizers.AdamW(learning_rate=base_lr, weight_decay=1e-5)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(ckpt_dir, f\"{model_name}.keras\"),\n",
    "            save_best_only=True, save_weights_only=False, monitor='val_accuracy'\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7),\n",
    "        keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.CSVLogger(os.path.join(log_dir, 'history.csv')),\n",
    "        keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "    ]\n",
    "\n",
    "    ema_cb = None\n",
    "    if USE_EMA:\n",
    "        ema_cb = ExponentialMovingAverageCallback(ema_decay=0.9999)\n",
    "        callbacks.append(ema_cb)\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
    "\n",
    "    # if EMA used, ensure final weights are ema for saving/evaluation (on_train_end should have set them)\n",
    "    if ema_cb is not None:\n",
    "        print(\"EMA applied at training end (if available).\")\n",
    "\n",
    "    # save final model copy (best already saved by checkpoint)\n",
    "    final_path = os.path.join(ckpt_dir, f\"{model_name}_final.keras\")\n",
    "    model.save(final_path)\n",
    "    print(f\"Saved final model to: {final_path}\")\n",
    "\n",
    "    # restore model weights back to original (if EMA was applied and we want model object restored)\n",
    "    if ema_cb is not None:\n",
    "        ema_cb.restore()\n",
    "\n",
    "    return history\n",
    "\n",
    "# ---------------------- TTA (with augmentation enabled) ----------------------\n",
    "def predict_with_tta(model, dataset, tta_steps=TTA_STEPS):\n",
    "    probs = []\n",
    "    for x_batch, _ in dataset:\n",
    "        x0 = tf.cast(x_batch, tf.float32)\n",
    "        batch_probs = np.zeros((x0.shape[0], NUM_CLASSES), dtype=np.float32)\n",
    "        for _ in range(tta_steps):\n",
    "            aug = data_augmentation(x0, training=True)   # force augmentation\n",
    "            preds = model.predict(aug, verbose=0)\n",
    "            batch_probs += preds\n",
    "        batch_probs /= float(tta_steps)\n",
    "        probs.append(batch_probs)\n",
    "    probs = np.vstack(probs)\n",
    "    return probs\n",
    "\n",
    "# ---------------------- ENSEMBLE / PSO ----------------------\n",
    "def ensemble_average(probs_list):\n",
    "    return np.mean(np.stack(probs_list, axis=0), axis=0)\n",
    "\n",
    "def ensemble_weighted(probs_list, weights):\n",
    "    w = np.array(weights).reshape(-1,1,1)\n",
    "    stacked = np.stack(probs_list, axis=0)\n",
    "    combined = np.sum(w * stacked, axis=0)\n",
    "    return combined\n",
    "\n",
    "class SimplePSO:\n",
    "    def __init__(self, n_particles, dim, probs_list, y_true, iters=100, w=0.72, c1=1.49, c2=1.49):\n",
    "        self.n_particles = n_particles\n",
    "        self.dim = dim\n",
    "        self.probs_list = probs_list\n",
    "        self.y_true = y_true\n",
    "        self.iters = iters\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.pos = np.random.rand(n_particles, dim)\n",
    "        self.pos = self.pos / np.sum(self.pos, axis=1, keepdims=True)\n",
    "        self.vel = np.zeros_like(self.pos)\n",
    "        self.pbest_pos = self.pos.copy()\n",
    "        self.pbest_val = np.array([self._fitness(p) for p in self.pos])\n",
    "        self.gbest_idx = np.argmin(self.pbest_val)\n",
    "        self.gbest_pos = self.pbest_pos[self.gbest_idx].copy()\n",
    "        self.gbest_val = self.pbest_val[self.gbest_idx]\n",
    "\n",
    "    def _fitness(self, weights):\n",
    "        combined = np.zeros_like(self.probs_list[0])\n",
    "        for w, probs in zip(weights, self.probs_list):\n",
    "            combined += w * probs\n",
    "        preds = np.argmax(combined, axis=1)\n",
    "        acc = accuracy_score(self.y_true, preds)\n",
    "        return -acc\n",
    "\n",
    "    def optimize(self):\n",
    "        for it in range(self.iters):\n",
    "            r1 = np.random.rand(self.n_particles, self.dim)\n",
    "            r2 = np.random.rand(self.n_particles, self.dim)\n",
    "            cognitive = self.c1 * r1 * (self.pbest_pos - self.pos)\n",
    "            social = self.c2 * r2 * (self.gbest_pos - self.pos)\n",
    "            self.vel = self.w * self.vel + cognitive + social\n",
    "            self.pos = self.pos + self.vel\n",
    "            self.pos = np.clip(self.pos, 1e-6, None)\n",
    "            self.pos = self.pos / np.sum(self.pos, axis=1, keepdims=True)\n",
    "            vals = np.array([self._fitness(p) for p in self.pos])\n",
    "            improved = vals < self.pbest_val\n",
    "            self.pbest_val[improved] = vals[improved]\n",
    "            self.pbest_pos[improved] = self.pos[improved]\n",
    "            gidx = np.argmin(self.pbest_val)\n",
    "            if self.pbest_val[gidx] < self.gbest_val:\n",
    "                self.gbest_val = self.pbest_val[gidx]\n",
    "                self.gbest_pos = self.pbest_pos[gidx].copy()\n",
    "            if it % max(1, self.iters//10) == 0 or it == self.iters - 1:\n",
    "                print(f\"PSO iter {it+1}/{self.iters}, best_acc = {-self.gbest_val:.4f}\")\n",
    "        return self.gbest_pos, -self.gbest_val\n",
    "\n",
    "# ---------------------- MAIN WORKFLOW ----------------------\n",
    "if __name__ == '__main__':\n",
    "    print(\"Building models (EffNetV2, ResNet50V2, SimpleCNN)\")\n",
    "    effnet = build_effnet(fine_tune_at=120)\n",
    "    resnet = build_resnet(fine_tune_at=80)\n",
    "    cnn = build_simple_cnn()\n",
    "\n",
    "    print(effnet.summary())\n",
    "    print(resnet.summary())\n",
    "    print(cnn.summary())\n",
    "\n",
    "    # Train models\n",
    "    compile_and_train(effnet, train_ds, val_ds, model_name='effnetv2_finetuned', epochs=EPOCHS, base_lr=1e-4, warmup_epochs=3)\n",
    "    compile_and_train(resnet, train_ds, val_ds, model_name='resnet50v2_finetuned', epochs=EPOCHS, base_lr=1e-4, warmup_epochs=3)\n",
    "    compile_and_train(cnn, train_ds, val_ds, model_name='simplecnn', epochs=EPOCHS, base_lr=1e-4, warmup_epochs=2)\n",
    "\n",
    "    # Evaluate with TTA\n",
    "    print(\"Computing TTA predictions (this may take a while)\")\n",
    "    eff_probs = predict_with_tta(effnet, val_ds, tta_steps=TTA_STEPS)\n",
    "    res_probs = predict_with_tta(resnet, val_ds, tta_steps=TTA_STEPS)\n",
    "    cnn_probs = predict_with_tta(cnn, val_ds, tta_steps=TTA_STEPS)\n",
    "\n",
    "    y_true = np.concatenate([y.numpy() for _, y in val_ds], axis=0)\n",
    "\n",
    "    # Simple average\n",
    "    avg_probs = ensemble_average([eff_probs, res_probs, cnn_probs])\n",
    "    avg_pred = np.argmax(avg_probs, axis=1)\n",
    "    avg_acc = accuracy_score(y_true, avg_pred)\n",
    "    print(f\"Average ensemble accuracy: {avg_acc:.4f}\")\n",
    "    print(classification_report(y_true, avg_pred))\n",
    "\n",
    "    # PSO optimize\n",
    "    print(\"Running PSO to find best ensemble weights...\")\n",
    "    pso = SimplePSO(n_particles=PSO_PARTICLES, dim=3, probs_list=[eff_probs, res_probs, cnn_probs], y_true=y_true, iters=PSO_ITERS)\n",
    "    best_w, best_acc = pso.optimize()\n",
    "    print(f\"Best weights: {best_w}, best_acc: {best_acc:.4f}\")\n",
    "\n",
    "    combined = ensemble_weighted([eff_probs, res_probs, cnn_probs], best_w)\n",
    "    comb_pred = np.argmax(combined, axis=1)\n",
    "    print(classification_report(y_true, comb_pred))\n",
    "\n",
    "    np.save(os.path.join(MODEL_DIR, 'ensemble_weights_3models.npy'), best_w)\n",
    "    print(\"All done. Models and ensemble weights saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc032d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
