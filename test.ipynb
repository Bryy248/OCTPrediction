{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4848c4fc",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68574909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import skew, kurtosis\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "964ffa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './RetinalOCT_Dataset/train/'\n",
    "test_path = './RetinalOCT_Dataset/test/'\n",
    "val_path = './RetinalOCT_Dataset/val/'\n",
    "classes = ['AMD','CNV','CSR','DME','DR','DRUSEN','MH','NORMAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71218c",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2a25f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(base_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, class_name in enumerate(classes):\n",
    "        folder_path = os.path.join(base_path, class_name)\n",
    "        for img in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edfd25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_dataset(train_path)\n",
    "val_images, val_labels = load_dataset(val_path)\n",
    "test_images, test_labels = load_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "683db12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('train.npz')\n",
    "train_images = train_data['images']\n",
    "train_labels = train_data['labels']\n",
    "\n",
    "test_data = np.load('test.npz')\n",
    "test_images = test_data['images']\n",
    "test_labels = test_data['labels']\n",
    "\n",
    "val_data = np.load('val.npz')\n",
    "val_images = val_data['images']\n",
    "val_labels = val_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1faa0d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  18400\n",
      "Val:  2800\n",
      "Test:  2800\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(train_images))\n",
    "print(\"Val: \", len(val_images))\n",
    "print(\"Test: \", len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be4d2a0",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82eb51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LBP_RADIUS = 2\n",
    "LBP_POINTS = 8 * LBP_RADIUS\n",
    "GABOR_ORIENTS = 4\n",
    "IMG_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb1e6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img):\n",
    "    if img.dtype != np.uint8:\n",
    "        img_u8 = (img*255).astype(np.uint8)\n",
    "    else:\n",
    "        img_u8 = img.copy()\n",
    "\n",
    "    if len(img_u8.shape) == 3:\n",
    "        img_gray = cv2.cvtColor(img_u8, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img_gray = img_u8\n",
    "\n",
    "    denoised = cv2.fastNlMeansDenoising(img_gray, h=10)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    norm = cv2.normalize(enhanced, None, 0, 1, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    mean_i = np.mean(norm)\n",
    "    std_i = np.std(norm)\n",
    "    skew_i = skew(norm.ravel())\n",
    "    kurt_i = kurtosis(norm.ravel())\n",
    "    p10, p50, p90 = np.percentile(norm, [10,50,90])\n",
    "\n",
    "    sobelx = cv2.Sobel(norm, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(norm, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    grad_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    sobel_mean = np.mean(grad_mag)\n",
    "    sobel_std = np.std(grad_mag)\n",
    "    edges = cv2.Canny((norm*255).astype(np.uint8), 50,150)\n",
    "    edge_density = np.sum(edges > 0)/edges.size\n",
    "\n",
    "    lbp = local_binary_pattern((norm*255).astype(np.uint8), LBP_POINTS, LBP_RADIUS, method='uniform')\n",
    "    n_bins = LBP_POINTS + 2\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins = n_bins, range=(0, n_bins))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist = hist/(hist.sum() + 1e-8)\n",
    "\n",
    "    gabor_means = []\n",
    "    for sigma in [2.0, 4.0, 8.0]:\n",
    "        for theta in (np.linspace(0, np.pi, GABOR_ORIENTS, endpoint=False)):\n",
    "            kernel = cv2.getGaborKernel((21,21), sigma=sigma, theta=theta, lambd=10.0, gamma=0.5, psi=0, ktype=cv2.CV_32F)\n",
    "            filtered = cv2.filter2D(norm, cv2.CV_32F, kernel)\n",
    "            gabor_means.append(np.mean(filtered))\n",
    "\n",
    "    gabor_means = np.array(gabor_means)\n",
    "\n",
    "    quantized = (norm * 7).astype(np.uint8)\n",
    "    glcm = graycomatrix(quantized, distances=[1], angles=[0], levels=8, symmetric=True, normed=True)\n",
    "    har_contrast = graycoprops(glcm, 'contrast')[0,0]\n",
    "    har_energy = graycoprops(glcm, 'energy')[0,0]\n",
    "    har_hom = graycoprops(glcm, 'homogeneity')[0,0]\n",
    "\n",
    "    lap_var = cv2.Laplacian((norm * 255).astype(np.uint8), cv2.CV_64F).var()\n",
    "\n",
    "    hog_feats = hog(norm, orientations=8, pixels_per_cell=(16,16), cells_per_block=(1,1), visualize=False, feature_vector=True)\n",
    "    hog_feats = hog_feats[:50]\n",
    "\n",
    "    orb = cv2.ORB_create(nfeatures=200)\n",
    "    kps = orb.detect((norm*255).astype(np.uint8), None)\n",
    "    orb_count = len(kps)\n",
    "\n",
    "    features = np.hstack([\n",
    "        sobel_mean, sobel_std, edge_density,\n",
    "        mean_i, std_i, skew_i, kurt_i, p10, p50, p90,\n",
    "        hist,\n",
    "        gabor_means,\n",
    "        har_contrast, har_energy, har_hom,\n",
    "        lap_var,\n",
    "        hog_feats,\n",
    "        orb_count\n",
    "    ])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef798a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_batch(images):    \n",
    "    features = []\n",
    "    total = len(images)\n",
    "    \n",
    "    for i, img in enumerate(images, 1):\n",
    "        feature = extract_features(img)\n",
    "        features.append(feature)\n",
    "\n",
    "        if i % (total//10) == 0:\n",
    "            percentage = int((i / total) * 100)\n",
    "            print(f\"==> {percentage}% done ({i}/{total} images)\\n\")\n",
    "    \n",
    "    print(\"Features Extraction Completed\\n\")\n",
    "    return np.vstack(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2fe6f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 10% done (1840/18400 images)\n",
      "\n",
      "==> 20% done (3680/18400 images)\n",
      "\n",
      "==> 30% done (5520/18400 images)\n",
      "\n",
      "==> 40% done (7360/18400 images)\n",
      "\n",
      "==> 50% done (9200/18400 images)\n",
      "\n",
      "==> 60% done (11040/18400 images)\n",
      "\n",
      "==> 70% done (12880/18400 images)\n",
      "\n",
      "==> 80% done (14720/18400 images)\n",
      "\n",
      "==> 90% done (16560/18400 images)\n",
      "\n",
      "==> 100% done (18400/18400 images)\n",
      "\n",
      "Features Extraction Completed\n",
      "\n",
      "==> 10% done (280/2800 images)\n",
      "\n",
      "==> 20% done (560/2800 images)\n",
      "\n",
      "==> 30% done (840/2800 images)\n",
      "\n",
      "==> 40% done (1120/2800 images)\n",
      "\n",
      "==> 50% done (1400/2800 images)\n",
      "\n",
      "==> 60% done (1680/2800 images)\n",
      "\n",
      "==> 70% done (1960/2800 images)\n",
      "\n",
      "==> 80% done (2240/2800 images)\n",
      "\n",
      "==> 90% done (2520/2800 images)\n",
      "\n",
      "==> 100% done (2800/2800 images)\n",
      "\n",
      "Features Extraction Completed\n",
      "\n",
      "==> 10% done (280/2800 images)\n",
      "\n",
      "==> 20% done (560/2800 images)\n",
      "\n",
      "==> 30% done (840/2800 images)\n",
      "\n",
      "==> 40% done (1120/2800 images)\n",
      "\n",
      "==> 50% done (1400/2800 images)\n",
      "\n",
      "==> 60% done (1680/2800 images)\n",
      "\n",
      "==> 70% done (1960/2800 images)\n",
      "\n",
      "==> 80% done (2240/2800 images)\n",
      "\n",
      "==> 90% done (2520/2800 images)\n",
      "\n",
      "==> 100% done (2800/2800 images)\n",
      "\n",
      "Features Extraction Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = extract_features_batch(train_images)\n",
    "X_val = extract_features_batch(val_images)\n",
    "X_test = extract_features_batch(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11537b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train.npz', images = train_images, labels = train_labels)\n",
    "np.savez('test.npz', images = test_images, labels = test_labels)\n",
    "np.savez('val.npz', images = val_images, labels = val_labels)\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('X_val.npy', X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30dd4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfaa3d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6746428571428571\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=1, gamma='scale', kernel='rbf')\n",
    "svm.fit(X_train_scaled, train_labels)\n",
    "\n",
    "val_pred = svm.predict(X_val_scaled)\n",
    "val_acc = np.mean(val_pred == val_labels)\n",
    "print(\"Validation accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d89c43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST RESULTS ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMD       0.99      1.00      0.99       350\n",
      "         CNV       0.58      0.60      0.59       350\n",
      "         CSR       0.73      0.78      0.75       350\n",
      "         DME       0.56      0.52      0.54       350\n",
      "          DR       0.71      0.71      0.71       350\n",
      "      DRUSEN       0.46      0.51      0.49       350\n",
      "          MH       0.63      0.57      0.60       350\n",
      "      NORMAL       0.61      0.56      0.58       350\n",
      "\n",
      "    accuracy                           0.66      2800\n",
      "   macro avg       0.66      0.66      0.66      2800\n",
      "weighted avg       0.66      0.66      0.66      2800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[350   0   0   0   0   0   0   0]\n",
      " [  0 211   0  56   0  68   0  15]\n",
      " [  3   0 274   0  23   0  50   0]\n",
      " [  0  59   0 182   0  65   0  44]\n",
      " [  0   0  32   0 248   0  70   0]\n",
      " [  0  58   0  44   0 180   0  68]\n",
      " [  0   0  71   0  78   0 201   0]\n",
      " [  1  33   0  42   0  77   0 197]]\n"
     ]
    }
   ],
   "source": [
    "test_pred = svm.predict(X_test_scaled)\n",
    "print(\"\\n=== TEST RESULTS ===\")\n",
    "print(classification_report(test_labels, test_pred, target_names=classes))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39dc88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
